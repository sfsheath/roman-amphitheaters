{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Creating CSV and Preliminary Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#import geopandas as gpd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Write to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"roman-amphitheaters.geojson\") as f:\n",
    "    j = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is one, I'd welcome a more pythonic approach. One that \n",
    "# accomodates the variable data model supported by JSON.\n",
    "\n",
    "d = []\n",
    "for feature in j['features']:\n",
    "    \n",
    "    # Check for optional properties\n",
    "\n",
    "    if 'latintoponym' in feature['properties'].keys():\n",
    "        latintoponym = feature['properties']['latintoponym']\n",
    "    else:\n",
    "        latintoponym = ''    \n",
    "\n",
    "    if 'welchid' in feature['properties'].keys():\n",
    "        welchid = feature['properties']['welchid']\n",
    "    else:\n",
    "        welchid = ''\n",
    "\n",
    "    if 'golvinid' in feature['properties'].keys():\n",
    "        golvinid = feature['properties']['golvinid']\n",
    "    else:\n",
    "        golvinid = ''\n",
    "\n",
    "    if 'buildingtype' in feature['properties'].keys():\n",
    "        buildingtype = feature['properties']['buildingtype']\n",
    "    else:\n",
    "        buildingtype = ''\n",
    "        \n",
    "    if 'buildingtype' in feature['properties'].keys():\n",
    "        buildingtype = feature['properties']['buildingtype']\n",
    "    else:\n",
    "        buildingtype = ''\n",
    " \n",
    "    if 'chronogroup' in feature['properties'].keys():\n",
    "        chronogroup = feature['properties']['chronogroup']\n",
    "    else:\n",
    "        chronogroup = ''\n",
    "\n",
    "    secondcentury = True\n",
    "    if 'exclude' in feature['properties'].keys():\n",
    "        secondcentury = False\n",
    "\n",
    "    if 'capacity' in feature['properties'].keys():\n",
    "        capacity = feature['properties']['capacity']['quantity']\n",
    "    else:\n",
    "        capacity = ''\n",
    "\n",
    "    if 'province' in feature['properties'].keys():\n",
    "        romanregion = feature['properties']['province']\n",
    "    elif 'region' in feature['properties'].keys():\n",
    "        romanregion = feature['properties']['region']\n",
    "    else:\n",
    "        romanregion = ''\n",
    "        \n",
    "    arenamajor = ''\n",
    "    arenaminor = ''\n",
    "    extmajor = ''\n",
    "    extminor = ''\n",
    "    exteriorheight = ''\n",
    "    if 'dimensions' in feature['properties'].keys():\n",
    "        dimensions = feature['properties']['dimensions']\n",
    "        \n",
    "        if 'arenamajor' in dimensions.keys():\n",
    "            arenamajor = dimensions['arenamajor']\n",
    "\n",
    "        if 'arenaminor' in dimensions.keys():\n",
    "            arenaminor = dimensions['arenaminor']\n",
    "            \n",
    "        if 'exteriormajor' in dimensions.keys():\n",
    "            extmajor = dimensions['exteriormajor']\n",
    "\n",
    "        if 'exteriorminor' in dimensions.keys():\n",
    "            extminor = dimensions['exteriorminor']\n",
    "            \n",
    "        if 'exteriorheight' in dimensions.keys():\n",
    "            exteriorheight = dimensions['exteriorheight']\n",
    "            \n",
    "    d.append((feature['id'],\n",
    "              feature['properties']['title'],\n",
    "              feature['properties']['label'],\n",
    "              latintoponym,\n",
    "              feature['properties']['pleiades'],\n",
    "              welchid,\n",
    "              golvinid,\n",
    "              buildingtype,\n",
    "              chronogroup,\n",
    "              secondcentury,\n",
    "              capacity,\n",
    "              feature['properties']['moderncountry'],\n",
    "              romanregion,\n",
    "              arenamajor,\n",
    "              arenaminor,\n",
    "              extmajor,\n",
    "              extminor,\n",
    "              exteriorheight,\n",
    "              feature['geometry']['coordinates'][0],\n",
    "              feature['geometry']['coordinates'][1],\n",
    "              feature['geometry']['coordinates'][2]))\n",
    "\n",
    "ramphs_df = pd.DataFrame(d, columns=(\n",
    " 'id',    # short id\n",
    " 'title', # longer title\n",
    " 'label', # short label\n",
    " 'latintoponym', # latin toponym\n",
    " 'pleiades', # pleiades https uri\n",
    " 'welchid',  # id in Welch\n",
    " 'golvinid', # id in Golvin\n",
    " 'buildingtype',  # usually 'amphitheater'\n",
    " 'chronogroup',   # label for the chronological group\n",
    " 'secondcentury', # is this an amphitheater that was in use in 2nd century\n",
    " 'capacity',    # capacity as integer\n",
    " 'modcountry',  # modern country\n",
    " 'romanregion', # province or augustan region of italy\n",
    " 'arenamajor', # long axis of arena in meters\n",
    " 'arenaminor', # short axis of arena in meters\n",
    " 'extmajor',   # long axis of exterior\n",
    " 'extminor', # short axis of exterior\n",
    " 'exteriorheight',   # height of exterior wall if known\n",
    " 'longitude', # latitude\n",
    " 'latitude', # longitude\n",
    " 'elevation'  # elevation in meters.\n",
    " )) \n",
    "\n",
    "ramphs_df[['capacity','elevation','arenamajor','arenaminor',\n",
    "        'extmajor','extminor','exteriorheight']] = ramphs_df[['capacity','elevation','arenamajor',\n",
    "        'arenaminor','extmajor','extminor','exteriorheight']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramphs_df.to_csv(\"roman-amphitheaters.csv\", index = False, quoting = csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramphs_df[['id','title','chronogroup','latintoponym','romanregion','modcountry','capacity',\n",
    "           'extmajor','extminor','arenamajor','arenaminor','latitude','longitude']].to_csv('tmp.csv', index = False, quoting = csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramphs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramphs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramphs_df[ramphs_df.secondcentury].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that CSV is readable\n",
    "# It would be nice if the \"numeric pattern\" string survived as strings.\n",
    "pd.read_csv(\"roman-amphitheaters.csv\", quoting = 2).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which have heights\n",
    "ramphs_df[ramphs_df.exteriorheight > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which don't have exteriormajor\n",
    "ramphs_df[pd.isnull(ramphs_df.extmajor)].sort_values(by = 'longitude')\\\n",
    "[['id','modcountry','latintoponym','golvinid','extmajor','arenamajor','latitude','longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramphs_df[ramphs_df.golvinid == '' ][['id','latintoponym','golvinid','extmajor','arenamajor','latitude','longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramphs_df[ramphs_df.latintoponym == '' ][['id','latintoponym','golvinid','extmajor','arenamajor','latitude','longitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = ramphs_df[ramphs_df.label.duplicated(keep = False)]\\\n",
    "[['id','pleiades','latintoponym','latitude','longitude']].sort_values('pleiades')\n",
    "\n",
    "len(dups) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = ramphs_df[ramphs_df.id.duplicated(keep = False)]\\\n",
    "[['id','pleiades','latintoponym','latitude','longitude']].sort_values('pleiades')\n",
    "\n",
    "len(dups) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = ramphs_df[ramphs_df.pleiades.duplicated(keep = False)]\\\n",
    "[['id','pleiades','latintoponym','latitude','longitude']].sort_values('pleiades')\n",
    "\n",
    "len(dups) == 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = ramphs_df[ramphs_df.latintoponym.duplicated(keep = False)]\\\n",
    "[['id','pleiades','latintoponym',\n",
    "  'latitude','longitude']].sort_values('pleiades')\n",
    "\n",
    "len(dups.query(\"latintoponym != ''\")) == 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdf = gpd.read_file(\"roman-amphitheaters.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdf.plot(color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is simple enough that all steps are in one cell\n",
    "c = []\n",
    "for cgrp in j['romanamphitheaterschronogroups']:\n",
    "    c.append((cgrp['id'],\n",
    "    cgrp['startdate'],\n",
    "    cgrp['enddate']))\n",
    "    \n",
    "chrono_df  = pd.DataFrame(c, columns=('chronogroup','startdate','enddate'))\n",
    "\n",
    "chrono_df.to_csv(\"chronogrps.csv\", index = False, quoting = csv.QUOTE_NONNUMERIC)\n",
    "chrono_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramphs_df.merge(chrono_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
